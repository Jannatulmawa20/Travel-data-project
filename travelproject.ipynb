{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecc14d1-14a6-4b21-a2c1-fe5b9b06f695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully.\n",
      "   Traveler_ID  Age  Gender Destination Travel_Type  Trip_Duration_Days  \\\n",
      "0            1   25    Male       Paris     Leisure                   7   \n",
      "1            2   34  Female    New York    Business                  10   \n",
      "2            3   40    Male       Tokyo     Leisure                   5   \n",
      "3            4   28  Female      London     Leisure                  14   \n",
      "4            5   22    Male        Rome    Business                   4   \n",
      "\n",
      "   Season Accommodation_Type  Budget_USD Frequent_Flyer  \n",
      "0  Summer              Hotel        1500            Yes  \n",
      "1  Winter             Airbnb        2500             No  \n",
      "2  Spring              Hotel        1200            Yes  \n",
      "3  Autumn             Hostel        1000            Yes  \n",
      "4  Summer              Hotel        1800             No  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load Data\n",
    "file_path = \"F:\\\\project data\\\\travel_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Data Loaded Successfully.\")\n",
    "print(data.head())  # Display the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3eb5a49-3b3d-4c99-b48f-1a226c7c9da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaned. No missing values or duplicates.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Cleaning\n",
    "# Handle missing values\n",
    "data = data.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "print(\"Data Cleaned. No missing values or duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60ed8ce-0fc8-446a-8bc9-0ef1a33955dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables encoded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = ['Gender', 'Destination', 'Travel_Type', 'Season', 'Accommodation_Type']\n",
    "\n",
    "# Check which columns exist in the dataset spicific data\n",
    "available_categorical_cols = [col for col in categorical_cols if col in data.columns]\n",
    "\n",
    "# Apply one-hot encoding to existing categorical columns\n",
    "if available_categorical_cols:\n",
    "    data = pd.get_dummies(data, columns=available_categorical_cols, drop_first=True)\n",
    "    print(\"Categorical variables encoded successfully.\")\n",
    "else:\n",
    "    print(\"No categorical columns to encode.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a74267-4b1e-466a-9abf-084c7e66d7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features before scaling:\n",
      "   Traveler_ID  Age  Trip_Duration_Days  Budget_USD\n",
      "0            1   25                   7        1500\n",
      "1            2   34                  10        2500\n",
      "2            3   40                   5        1200\n",
      "3            4   28                  14        1000\n",
      "4            5   22                   4        1800\n",
      "Numeric features after scaling:\n",
      "   Traveler_ID       Age  Trip_Duration_Days  Budget_USD\n",
      "0    -1.566699 -1.013295           -0.386739   -0.317021\n",
      "1    -1.218544 -0.265782            0.668004    1.268085\n",
      "2    -0.870388  0.232559           -1.089902   -0.792553\n",
      "3    -0.522233 -0.764124            2.074330   -1.109575\n",
      "4    -0.174078 -1.262465           -1.441483    0.158511\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Specify file path\n",
    "file_path = \"F:\\\\project data\\\\travel_data.csv\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"File not found at {file_path}. Please check the path.\")\n",
    "else:\n",
    "    # Load Data\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Make a copy of the dataset for preprocessing\n",
    "    clean_data = data.copy()\n",
    "\n",
    "    # Select numeric columns\n",
    "    numeric_cols = clean_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Show numeric features before scaling\n",
    "    print(\"Numeric features before scaling:\")\n",
    "    print(clean_data[numeric_cols].head())\n",
    "\n",
    "    # Apply StandardScaler to scale numeric features\n",
    "    scaler = StandardScaler()\n",
    "    clean_data[numeric_cols] = scaler.fit_transform(clean_data[numeric_cols])\n",
    "\n",
    "    # Show numeric features after scaling\n",
    "    print(\"Numeric features after scaling:\")\n",
    "    print(clean_data[numeric_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9da053bc-4fd3-4ee8-a698-f930515819ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (7, 9)\n",
      "Validation Data Shape: (1, 9)\n",
      "Testing Data Shape: (2, 9)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Splitting Data\n",
    "# Define a target column (for demonstration purposes, assume 'Frequent_Flyer' is the target)\n",
    "target = 'Frequent_Flyer'\n",
    "X = clean_data.drop(columns=[target])\n",
    "y = clean_data[target]\n",
    "\n",
    "# Split the dataset into training (70%) and temporary (30%) datasets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temporary dataset into validation (50%) and testing (50%) datasets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display processed data shapes\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Validation Data Shape:\", X_val.shape)\n",
    "print(\"Testing Data Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca70315-0bab-47d3-b947-95a58fa7ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical variables encoded.\n",
      "Validation Accuracy: 1.00\n",
      "Test Accuracy: 0.50\n",
      "Data processing and model evaluation complete. Files saved:\n",
      "Train: ./processed_data\\travel_data_train.csv\n",
      "Validation: ./processed_data\\travel_data_val.csv\n",
      "Test: ./processed_data\\travel_data_test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load Data\n",
    "file_path = \"F:\\\\project data\\\\travel_data.csv\"   # Updated file path for the uploaded dataset\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"The file was not found at: {file_path}\")\n",
    "else:\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "\n",
    "    # Step 2: Data Cleaning\n",
    "    data = data.dropna()  # Drop rows with missing values\n",
    "    data = data.drop_duplicates()  # Remove duplicates\n",
    "\n",
    "    # Step 3: Data Transformation\n",
    "    # Identify categorical columns\n",
    "    categorical_cols = ['Gender', 'Destination', 'Travel_Type', 'Season', 'Accommodation_Type']\n",
    "\n",
    "    # Apply one-hot encoding to all categorical columns\n",
    "    data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "    print(\"Categorical variables encoded.\")\n",
    "\n",
    "    # Step 4: Define Features (X) and Target (y)\n",
    "    target = 'Frequent_Flyer'\n",
    "    if target not in data.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in dataset.\")\n",
    "\n",
    "    X = data.drop(columns=[target])\n",
    "    y = data[target]\n",
    "\n",
    "    # Step 5: Split the Data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Step 6: Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Step 7: Train and Evaluate a Model\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Validation evaluation\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
    "\n",
    "    # Test evaluation\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # Step 8: Save Processed Datasets\n",
    "    output_dir = \"./processed_data\"  # Save in current directory\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "    try:\n",
    "        # Convert transformed data back to DataFrame for saving\n",
    "        X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "        X_val_df = pd.DataFrame(X_val, columns=X.columns)\n",
    "        X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "        # Save datasets\n",
    "        X_train_df.to_csv(os.path.join(output_dir, \"travel_data_train.csv\"), index=False)\n",
    "        X_val_df.to_csv(os.path.join(output_dir, \"travel_data_val.csv\"), index=False)\n",
    "        X_test_df.to_csv(os.path.join(output_dir, \"travel_data_test.csv\"), index=False)\n",
    "\n",
    "        y_train.to_csv(os.path.join(output_dir, \"travel_data_train_labels.csv\"), index=False)\n",
    "        y_val.to_csv(os.path.join(output_dir, \"travel_data_val_labels.csv\"), index=False)\n",
    "        y_test.to_csv(os.path.join(output_dir, \"travel_data_test_labels.csv\"), index=False)\n",
    "\n",
    "        print(\"Data processing and model evaluation complete. Files saved:\")\n",
    "        print(f\"Train: {os.path.join(output_dir, 'travel_data_train.csv')}\")\n",
    "        print(f\"Validation: {os.path.join(output_dir, 'travel_data_val.csv')}\")\n",
    "        print(f\"Test: {os.path.join(output_dir, 'travel_data_test.csv')}\")\n",
    "\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad995fe2-eab6-4eca-9aed-9f9f2e7582b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe59a64-97a1-46b0-ae49-34b7b70d7b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
